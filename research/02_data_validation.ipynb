{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f14cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce02a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ajay\\\\Desktop\\\\myPortfolio\\\\CommentAnalysis'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1556f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0350e02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ajay\\\\Desktop\\\\myPortfolio\\\\CommentAnalysis'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "826abf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    DATA_VALIDATION_DIR: Path\n",
    "    train_file_path: Path\n",
    "    test_file_path: Path\n",
    "    drift_report_file_path: Path\n",
    "    validation_status_file: Path\n",
    "    test_size:float\n",
    "    local_file_path:Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f543bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CommentAnalysis.constants import *\n",
    "from src.CommentAnalysis.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f83719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema=read_yaml(SCHEMA_FILE_PATH)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        config2=self.config.data_ingestion\n",
    "\n",
    "\n",
    "        create_directories([config.DATA_VALIDATION_DIR])\n",
    "\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            DATA_VALIDATION_DIR=config.DATA_VALIDATION_DIR,\n",
    "            train_file_path=config.train_file_path,\n",
    "            test_file_path=config.test_file_path,\n",
    "            drift_report_file_path=config.drift_report_file_path,\n",
    "            validation_status_file=config.validation_status_file,\n",
    "            test_size=self.params.test_size,\n",
    "            local_file_path=config2.local_data_file\n",
    "            \n",
    "        )\n",
    "\n",
    "        return data_validation_config\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "940b0891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from evidently import Report\n",
    "from evidently.presets import DataDriftPreset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.CommentAnalysis import logger\n",
    "from src.CommentAnalysis.constants import SCHEMA_FILE_PATH\n",
    "from src.CommentAnalysis.utils.common import save_json, read_yaml\n",
    "\n",
    "\n",
    "class DataValidation:\n",
    "    def __init__(self, data_validation_config):\n",
    "        try:\n",
    "            self.data_validation_config = data_validation_config\n",
    "            self._schema_config = read_yaml(SCHEMA_FILE_PATH)\n",
    "        except Exception as e:\n",
    "            raise Exception(e, sys)\n",
    "\n",
    "    def validate_number_of_columns(self, df: DataFrame) -> bool:\n",
    "        try:\n",
    "            expected_cols = len(self._schema_config[\"columns\"])\n",
    "            status = len(df.columns) == expected_cols\n",
    "            logger.info(f\"Is required column count correct: {status}\")\n",
    "            return status\n",
    "        except Exception as e:\n",
    "            raise Exception(e, sys)\n",
    "\n",
    "    def is_column_exist(self, df: DataFrame) -> bool:\n",
    "        try:\n",
    "            missing_cols = [\n",
    "                col for col in self._schema_config[\"categorical_columns\"]\n",
    "                if col not in df.columns\n",
    "            ]\n",
    "            if missing_cols:\n",
    "                logger.info(f\"Missing categorical columns: {missing_cols}\")\n",
    "                return False\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            raise Exception(e, sys)\n",
    "\n",
    "    @staticmethod\n",
    "    def read_data(file_path) -> DataFrame:\n",
    "        try:\n",
    "            return pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            raise Exception(e, sys)\n",
    "\n",
    "    def detect_dataset_drift(self, reference_df: DataFrame, current_df: DataFrame) -> bool:\n",
    "        \"\"\"\n",
    "        Run drift detection and save report. Return True if drift detected, False otherwise.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            report = Report(metrics=[DataDriftPreset()])\n",
    "            data_drift=report.run(reference_data=reference_df, current_data=current_df)\n",
    "\n",
    "            data_drift.save_json(self.data_validation_config.drift_report_file_path)\n",
    "            logger.info(f\"Drift report saved at {self.data_validation_config.drift_report_file_path}\")\n",
    "\n",
    "            with open(self.data_validation_config.drift_report_file_path) as f:\n",
    "                json_report = json.load(f)\n",
    "\n",
    "            # robust check\n",
    "            drift_detected = False\n",
    "            for metric in json_report['metrics']:\n",
    "                if 'DriftedColumnsCount' in metric['metric_id']:\n",
    "                    count = metric['value'].get('count', 0)\n",
    "                    share = metric['value'].get('share', 0.0)\n",
    "                    logger.info(f\"Drifted columns: {count} ({share*100:.2f}%)\")\n",
    "                    if count > 0 or share > 0:\n",
    "                        drift_detected = True\n",
    "            logger.info(f\"Dataset drift detected: {drift_detected}\")\n",
    "            return drift_detected\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(e, sys)\n",
    "\n",
    "    def initiate_data_validation(self) -> dict:\n",
    "        \"\"\"\n",
    "        Run the entire validation workflow.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            validation_error_msg = \"\"\n",
    "            logger.info(\"Starting data validation\")\n",
    "\n",
    "            df = self.read_data(self.data_validation_config.local_file_path)\n",
    "\n",
    "            if not self.validate_number_of_columns(df):\n",
    "                validation_error_msg += \"Column count mismatch. \"\n",
    "\n",
    "            if not self.is_column_exist(df):\n",
    "                validation_error_msg += \"Missing required columns. \"\n",
    "\n",
    "            validation_status = len(validation_error_msg) == 0\n",
    "\n",
    "            train_path, test_path = None, None\n",
    "\n",
    "            if validation_status:\n",
    "                reference_df = df.copy()\n",
    "                current_df = df.copy()\n",
    "\n",
    "                drift_status = self.detect_dataset_drift(reference_df, current_df)\n",
    "\n",
    "                if drift_status:\n",
    "                    validation_error_msg += \"Drift detected. \"\n",
    "                    validation_status = False\n",
    "                else:\n",
    "                    logger.info(\"No significant drift detected.\")\n",
    "\n",
    "                if validation_status:\n",
    "                    train_df, test_df = train_test_split(\n",
    "                        df,\n",
    "                        test_size=self.data_validation_config.test_size,\n",
    "                        random_state=42,\n",
    "                        stratify=df[self._schema_config[\"categorical_columns\"][0]]\n",
    "                    )\n",
    "                    train_path = self.data_validation_config.train_file_path\n",
    "                    test_path = self.data_validation_config.test_file_path\n",
    "\n",
    "                    train_df.to_csv(train_path, index=False)\n",
    "                    test_df.to_csv(test_path, index=False)\n",
    "\n",
    "                    logger.info(f\"Train file saved to: {train_path}\")\n",
    "                    logger.info(f\"Test file saved to: {test_path}\")\n",
    "                else:\n",
    "                    logger.info(\"Validation failed â†’ skipping train/test split.\")\n",
    "            else:\n",
    "                logger.info(f\"Validation failed: {validation_error_msg}\")\n",
    "\n",
    "            validation_dict = {\n",
    "                \"validation_status\": validation_status,\n",
    "                \"validation_message\": validation_error_msg,\n",
    "                \"valid_train_file_path\": train_path,\n",
    "                \"valid_test_file_path\": test_path,\n",
    "                \"drift_report_file_path\": self.data_validation_config.drift_report_file_path,\n",
    "            }\n",
    "\n",
    "            save_json(self.data_validation_config.validation_status_file, validation_dict)\n",
    "            return validation_dict\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(e, sys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "482684a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-07 07:06:49,719: INFO: common: YAML file loaded successfully: config\\config.yaml]\n",
      "[2025-07-07 07:06:49,724: INFO: common: YAML file loaded successfully: params.yaml]\n",
      "[2025-07-07 07:06:49,729: INFO: common: YAML file loaded successfully: config\\schema.yaml]\n",
      "[2025-07-07 07:06:49,733: INFO: common: Created directory: artifacts]\n",
      "[2025-07-07 07:06:49,737: INFO: common: Created directory: artifacts/data_validation]\n",
      "[2025-07-07 07:06:49,780: INFO: common: YAML file loaded successfully: config\\schema.yaml]\n",
      "[2025-07-07 07:06:49,783: INFO: 3570935567: Starting data validation]\n",
      "[2025-07-07 07:06:50,222: INFO: 3570935567: Is required column count correct: True]\n",
      "[2025-07-07 07:07:08,733: INFO: 3570935567: Drift report saved at artifacts/data_validation/drift_report.json]\n",
      "[2025-07-07 07:07:08,740: INFO: 3570935567: Drifted columns: 0.0 (0.00%)]\n",
      "[2025-07-07 07:07:08,742: INFO: 3570935567: Dataset drift detected: False]\n",
      "[2025-07-07 07:07:08,747: INFO: 3570935567: No significant drift detected.]\n",
      "[2025-07-07 07:07:09,638: INFO: 3570935567: Train file saved to: artifacts/data_validation/training_data.csv]\n",
      "[2025-07-07 07:07:09,642: INFO: 3570935567: Test file saved to: artifacts/data_validation/test_data.csv]\n",
      "[2025-07-07 07:07:09,673: INFO: common: JSON file saved: artifacts/data_validation/data_validation_artifact.json]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_validation_config = config.get_data_validation_config()\n",
    "    data_validation = DataValidation(data_validation_config=data_validation_config)\n",
    "    data_validation.initiate_data_validation() \n",
    "   \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d024e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
